# LinuxMonitoring v2.0

Мониторинг и исследование состояния системы в реальном времени.

## Contents

1. [Генератор файлов](#part-1-генератор-файлов)  
2. [Засорение файловой системы](#part-2-засорение-файловой-системы)  
3. [Очистка файловой системы](#part-3-очистка-файловой-системы)  
4. [Генератор логов](#part-4-генератор-логов)  
5. [Мониторинг](#part-5-мониторинг)  
6. [GoAccess](#part-6-goaccess)  
7. [Prometheus и Grafana](#part-7-prometheus-и-grafana)  
8. [Готовый дашборд](#part-8-готовый-дашборд)  
9. [Дополнительно. Свой node_exporter] (#part-9-дополнительно-свой-node_exporter)

## Part 1. Генератор файлов

> Скрипт генерирует файлы заданного размера в указанной директории. В качестве параметров также передаются символы для генерации имен папок и файлов и количество папок и файлов в них.

**Параметр 1** - это абсолютный путь. \
**Параметр 2** - количество вложенных папок. \
**Параметр 3** - список букв английского алфавита, используемый в названии папок (не более 7 знаков). \
**Параметр 4** - количество файлов в каждой созданной папке. \
**Параметр 5** - список букв английского алфавита, используемый в имени файла и расширении (не более 7 знаков для имени, не более 3 знаков для расширения). \
**Параметр 6** - размер файлов (в килобайтах, но не более 100).  

```bash
bash main.sh /opt/test 5 high 3 qwer.txt 23
```

_Информация о созданных файлах записывается в log_file в той директории, где был запущен скрипт._

## Part 2. Засорение файловой системы

> Скрипт генерирует файлы по всей системе до тех пор, пока больше 1 Гб свободного места в корневой директории. На ввод принимаются символы для имен директорий, файлов (с расширением) и размер в Mb.

**Параметр 1** - список букв английского алфавита, используемый в названии папок (не более 7 знаков). \
**Параметр 2** - список букв английского алфавита, используемый в имени файла и расширении (не более 7 знаков для имени, не более 3 знаков для расширения). \
**Параметр 3** - размер файла (в Мегабайтах, но не более 100).  

```bash
bash main.sh az az.az 3Mb
```

_Информация о созданных файлах записывается в log_file в той директории, где был запущен скрипт._

## Part 3. Очистка файловой системы

> Скрипт чистит систему тремя способами: 1) по файлу с логами; 2) по времени создания (не затрагивает системных); 3) по маске, используемой в пунктах выше.

1. По лог файлу
2. По дате и времени создания
3. По маске имени (т.е. символы, нижнее подчёркивание и дата).  

- Протестировать можно, запустив скрипт test.sh (less для удобства просмотра вывода):

```bash
bash test.sh | less
```

## Part 4. Генератор логов

> Скрпит генерирует 5 файлов с логами nginx в combined формате.

1. IP (любые корректные, т.е. не должно быть ip вида 999.111.777.777)
2. Коды ответа (200, 201, 400, 401, 403, 404, 500, 501, 502, 503)
3. Методы (GET, POST, PUT, PATCH, DELETE)
4. Даты (в рамках заданного дня лога, должны идти по увеличению)
5. URL запроса агента
6. Агенты (Mozilla, Google Chrome, Opera, Safari, Internet Explorer, Microsoft Edge, Crawler and bot, Library and net tool)

|http-код| Значение |
|--|--|
|200|OK|
|201|Created|
|400|Bad Request|
|401|Unauthorized|
|403|Forbidden|
|404|Not Found|
|500|Internal Server Error|
|501|Not Implemented|
|502|Bad Gateway|
|503|Service Unavailable|


## Part 5. Мониторинг

> Простой анализ логов в терминале. В зависимости от выбранной аргументы скрипт выведет: 1 - Все записи, отсортированные по коду ответа; 2 - Все уникальные IP, встречающиеся в записях; 3 - Все запросы с ошибками (код ответа - 4хх или 5хх); 4 - Все уникальные IP, которые встречаются среди ошибочных запросов.

1. Все записи, отсортированные по коду ответа
2. Все уникальные IP, встречающиеся в записях
3. Все запросы с ошибками (код ответа - 4хх или 5хх)
4. Все уникальные IP, которые встречаются среди ошибочных запросов

- Протестировать можно через готовый скрипт.

```sh
bash main.sh 1
```

## Part 6. **GoAccess**

> Воспользуемся готовой утилитой для анализа из прошлой логов. Установим goaccess на ubuntu и сгенерируем html-страничку с анализом логов.

![part 6](src/06/image.png)

## Part 7. **Prometheus** и **Grafana**

|Утилита| Порт | Обзор |
|--|--|--|
|Prometheus|9090|Получает метрики из разных сервисов и собирает их в одном месте.|
|Node exporter|9100|Небольшое приложение, собирающее метрики операционной системы и предоставляющее к ним доступ по HTTP. Prometheus собирает данные с одного или нескольких экземпляров Node Exporter.|
|Grafana|3000|Grafana отображает данные из Prometheus в виде графиков и диаграмм, организованных в дашборды.|

##### Установить и настроить **Prometheus** и **Grafana** на виртуальную машину

1. Обновим систему:

```bash
sudo apt-get update
sudo apt-get upgrade
```

- ДАЛЬШЕ ТОЛЬКО С VPN

2. Grafana:

```bash
sudo dpkg -i grafana-enterprise_9.5.1_amd64.deb
sudo systemctl start grafana-server
sudo systemctl enable grafana-server
sudo systemctl status grafana-server
```

- логин && пароль - admin

3. Prometheus был установлен через менеджер пакетов:

- Для проверки запуска на ubuntu:
```bash
curl 127.0.0.1:9090
```

![prometheus](src/07/image-1.png)

4. Node_exporter был установлен аналогично grafana - через скачивание архива в общую папку с использованием vpn. Ссылка: https://ourcodeworld.com/articles/read/1686/how-to-install-prometheus-node-exporter-on-ubuntu-2004

- Для проверки запуска на ubuntu:
```bash
curl 127.0.0.1:9100
```

- В браузере:

![node_exporter](src/07/image-2.png)

5. Для того, чтобы отразить метрики в grafana из prometheus, добавим data source "Prometheus" (инструкция: https://prometheus.io/docs/visualization/grafana/#creating-a-prometheus-data-source) и создадим дашборд. Используемые метрики:

- ЦПУ: `100 - (avg by (instance) (irate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100)`

- Свободная и доступная память: `node_memory_MemFree_bytes`, `node_memory_MemAvail_bytes`

- Свободное место: `node_filesystem_avail_bytes/node_filesystem_size_bytes*100`

- Количество операций ввода/вывода на жестком диске: `node_disk_io_now`

_Колодцы на графиках свзяны с свободным местом (Filesystem available size) и пики на графике с операциями ввода-вывода отражают запуск скрипта из 02/ с засорением системы и последующее удаление сгенерированных файлов._

_Пики на графиках с ЦПУ сопряжены со стресс-тестированием системы._

![7-part](src/07/image-3.png)

6. Запуск стресс-тестирования:

```bash
stress -c 2 -i 1 -m 1 --vm-bytes 32M -t 10s
```

## Part 8. Готовый дашборд

1. Скачаем Node Exporter Quickstart and Dashboard с официального сайта Grafana Labs: https://grafana.com/api/dashboards/13978/revisions/1/download.

2. Перейдем по ссылке http://localhost:3000/dashboard/import и загрузим скачанный json.

3. Готово! Провел те же тесты, что в предыдущем таске, результаты на графах.

![part-8](src/08/image-4.png)
![part-8.2](src/08/image-5.png)

4. Склонируем машину и во внутренней сети настроим статическую маршрутизацию между двумя машинами. Склонированная машина будет сервером, исходная машина - клиентом. На сервере запустим `iperf3 -s`, на клиенте - `iperf3 -c <ip_addr>`. С запуском сетевой трафик во внутренней сети (enp0s8) заметно возрастет, что показывают пики на графике:

- ping 

![ping](src/08/image-7.png)

- iperf3

![iperf3](src/08/image-8.png)

- нагрузка

![нагрузка](src/08/image-9.png)

## Part 9. Дополнительно. Свой *node_exporter*

Написать bash-скрипт или программу на Си, которая собирает информацию по базовым метрикам системы (ЦПУ, оперативная память, жесткий диск (объем)).
Скрипт или программа должна формировать html страничку по формату **Prometheus**, которую будет отдавать **nginx**. \
Саму страничку обновлять можно как внутри bash-скрипта или программы (в цикле), так и при помощи утилиты cron, но не чаще, чем раз в 3 секунды.

##### Поменять конфигурационный файл **Prometheus**, чтобы он собирал информацию с созданной вами странички.

##### Провести те же тесты, что и в [Части 7](#part-7-prometheus-и-grafana)

![node_exporter](src/09/image-10.jpg)